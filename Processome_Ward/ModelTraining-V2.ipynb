{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "manufactured-scanning",
   "metadata": {},
   "source": [
    "# Word2Vec Model training\n",
    "\n",
    "We are going to train our model on four data sources\n",
    "1. The nodes themselves\n",
    "2. recipe data (external)\n",
    "3. groceryDB\n",
    "5. text8 Corpus (Wikipedia dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "streaming-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NodeSim Tool:\n",
    "from NodeSim import NodeSim\n",
    "\n",
    "\n",
    "# Word2Vec:\n",
    "import gensim.downloader as api\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# other\n",
    "import json\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-angola",
   "metadata": {},
   "source": [
    "## Read in Nodes\n",
    "\n",
    "**Note:** for model training we are using the labels, including the information in the parenthesis. The way we will differentiate the information within the parenthesis will be when we actually run labels through the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "naughty-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "df = pd.read_csv(\"nodes.csv\")\n",
    "slim = df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fresh-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process labels\n",
    "\n",
    "NS = NodeSim()\n",
    "\n",
    "# these terms were hand-picked after looking at some of the most frequent words..\n",
    "termsToBeRemoved = [\"(efsa foodex2)\",\"(efsa foodex)\",\"and similar\",\"probably\", \"other\",\"food\",\"(us cfr)\",\"(gs gpc)\",\"products\", \"product\",\"obsolete\"]\n",
    "\n",
    "\n",
    "labels = NS.processStrings(labels = slim, removeParentheses = True, \n",
    "                           termsToBeRemoved = termsToBeRemoved, removeStopWords = True, \n",
    "                           locateBigrams = True, bigramMinCount = 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-convert",
   "metadata": {},
   "source": [
    "#### Preview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "solved-palace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 21675\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>clean</th>\n",
       "      <th>parentheses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>33770 - sangria (efsa foodex2)</td>\n",
       "      <td>[sangria]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>coffee bean (whole or ground)</td>\n",
       "      <td>[coffee, bean]</td>\n",
       "      <td>[whole, ground]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pudding sugar-free instant</td>\n",
       "      <td>[pudding, sugar, free, instant]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vegetable shortening</td>\n",
       "      <td>[vegetable, shortening]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>soup base flavored with beef extract</td>\n",
       "      <td>[soup, base, flavored, with, beef, extract]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>beef eye round (roasted)</td>\n",
       "      <td>[beef, eye, round]</td>\n",
       "      <td>[roasted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>laminate tube; unlined aluminum ends</td>\n",
       "      <td>[laminate tube, unlined, aluminum, ends]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>43050 - macadamia flavour (efsa foodex2)</td>\n",
       "      <td>[macadamia, flavour]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ice krill</td>\n",
       "      <td>[ice, krill]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>neogastropod</td>\n",
       "      <td>[neogastropod]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>guava (dried)</td>\n",
       "      <td>[guava]</td>\n",
       "      <td>[dried]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fruit sherbet (artificially sweetened)</td>\n",
       "      <td>[fruit, sherbet]</td>\n",
       "      <td>[artificially, sweetened]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>40200 - salads (efsa foodex2)</td>\n",
       "      <td>[salads]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>soursop (whole; raw)</td>\n",
       "      <td>[soursop]</td>\n",
       "      <td>[whole, raw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>papaya concentrate (nonnutritively sweetened)</td>\n",
       "      <td>[papaya, concentrate]</td>\n",
       "      <td>[nonnutritively, sweetened]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              raw  \\\n",
       "10                 33770 - sangria (efsa foodex2)   \n",
       "11                  coffee bean (whole or ground)   \n",
       "12                     pudding sugar-free instant   \n",
       "13                           vegetable shortening   \n",
       "14           soup base flavored with beef extract   \n",
       "15                       beef eye round (roasted)   \n",
       "16           laminate tube; unlined aluminum ends   \n",
       "17       43050 - macadamia flavour (efsa foodex2)   \n",
       "18                                      ice krill   \n",
       "19                                   neogastropod   \n",
       "20                                  guava (dried)   \n",
       "21         fruit sherbet (artificially sweetened)   \n",
       "22                  40200 - salads (efsa foodex2)   \n",
       "23                           soursop (whole; raw)   \n",
       "24  papaya concentrate (nonnutritively sweetened)   \n",
       "\n",
       "                                          clean                  parentheses  \n",
       "10                                    [sangria]                           []  \n",
       "11                               [coffee, bean]              [whole, ground]  \n",
       "12              [pudding, sugar, free, instant]                           []  \n",
       "13                      [vegetable, shortening]                           []  \n",
       "14  [soup, base, flavored, with, beef, extract]                           []  \n",
       "15                           [beef, eye, round]                    [roasted]  \n",
       "16     [laminate tube, unlined, aluminum, ends]                           []  \n",
       "17                         [macadamia, flavour]                           []  \n",
       "18                                 [ice, krill]                           []  \n",
       "19                               [neogastropod]                           []  \n",
       "20                                      [guava]                      [dried]  \n",
       "21                             [fruit, sherbet]    [artificially, sweetened]  \n",
       "22                                     [salads]                           []  \n",
       "23                                    [soursop]                 [whole, raw]  \n",
       "24                        [papaya, concentrate]  [nonnutritively, sweetened]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('size:', len(labels))\n",
    "labels[10:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-consent",
   "metadata": {},
   "source": [
    "## Read Recipe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "southwest-writing",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = list()\n",
    "\n",
    "with open('../recipes.json') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "    # just need to read the json data into a list of words.\n",
    "    for r in data:\n",
    "        myRecipe = [r['cuisine']]\n",
    "        myRecipe.extend(r['ingredients'])\n",
    "        recipes.append(myRecipe)\n",
    "        \n",
    "# this data is already clean, so no further processing is neccessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-bidder",
   "metadata": {},
   "source": [
    "#### Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "progressive-summit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 39774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['greek',\n",
       "  'romaine lettuce',\n",
       "  'black olives',\n",
       "  'grape tomatoes',\n",
       "  'garlic',\n",
       "  'pepper',\n",
       "  'purple onion',\n",
       "  'seasoning',\n",
       "  'garbanzo beans',\n",
       "  'feta cheese crumbles']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('size:', len(recipes))\n",
    "recipes[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-aaron",
   "metadata": {},
   "source": [
    "## Read Grocery DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "industrial-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery = pd.read_excel(\"../GroceryDB.xlsx\", engine='openpyxl')\n",
    "\n",
    "# we are going to use the name and group of each listing.. so we are just going to concat \n",
    "# those strings and then run them through our processor.\n",
    "groceryClean = []\n",
    "\n",
    "for i in range(len(grocery)):\n",
    "    if(type(grocery['name'][i]) == str and type(grocery['group'][i]) == str):\n",
    "        concat = grocery['name'][i] + \" \" + grocery['group'][i]\n",
    "        groceryClean.append(concat)\n",
    "        \n",
    "termsToBeRemoved = ['each', 'lb']\n",
    "\n",
    "grocery = NS.processStrings(labels = groceryClean, removeParentheses = False, \n",
    "                            removeStopWords = True, termsToBeRemoved = termsToBeRemoved,\n",
    "                            locateBigrams = True, bigramMinCount = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-employee",
   "metadata": {},
   "source": [
    "#### Preview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "royal-might",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 14823\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bananas, each Bananas &amp; Plantains</td>\n",
       "      <td>[bananas, bananas, plantains]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fresh Red Seedless Grapes bag Grapes</td>\n",
       "      <td>[fresh, red, seedless, grapes, bag, grapes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hass Avocados, each Avocados</td>\n",
       "      <td>[hass, avocados, avocados]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lemons, each Citrus</td>\n",
       "      <td>[lemons, citrus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cantaloupe, each Melons</td>\n",
       "      <td>[cantaloupe, melons]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Limes, each Citrus</td>\n",
       "      <td>[limes, citrus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pineapple Tropical &amp; Exotic Fruit</td>\n",
       "      <td>[pineapple, tropical exotic, fruit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fresh Strawberries, 1 lb Berries</td>\n",
       "      <td>[fresh, strawberries, berries]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yellow Mangoes, each Tropical &amp; Exotic Fruit</td>\n",
       "      <td>[yellow, mangoes, tropical exotic, fruit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fresh Mangoes, each Tropical &amp; Exotic Fruit</td>\n",
       "      <td>[fresh, mangoes, tropical exotic, fruit]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw  \\\n",
       "0             Bananas, each Bananas & Plantains   \n",
       "1          Fresh Red Seedless Grapes bag Grapes   \n",
       "2                  Hass Avocados, each Avocados   \n",
       "3                           Lemons, each Citrus   \n",
       "4                       Cantaloupe, each Melons   \n",
       "5                            Limes, each Citrus   \n",
       "6             Pineapple Tropical & Exotic Fruit   \n",
       "7              Fresh Strawberries, 1 lb Berries   \n",
       "8  Yellow Mangoes, each Tropical & Exotic Fruit   \n",
       "9   Fresh Mangoes, each Tropical & Exotic Fruit   \n",
       "\n",
       "                                         clean  \n",
       "0                [bananas, bananas, plantains]  \n",
       "1  [fresh, red, seedless, grapes, bag, grapes]  \n",
       "2                   [hass, avocados, avocados]  \n",
       "3                             [lemons, citrus]  \n",
       "4                         [cantaloupe, melons]  \n",
       "5                              [limes, citrus]  \n",
       "6          [pineapple, tropical exotic, fruit]  \n",
       "7               [fresh, strawberries, berries]  \n",
       "8    [yellow, mangoes, tropical exotic, fruit]  \n",
       "9     [fresh, mangoes, tropical exotic, fruit]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('size:', len(grocery))\n",
    "grocery[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "standard-consensus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['limes', 'citrus']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grocery['clean'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-warning",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "\n",
    "**FUNCTION :** trainModel  \n",
    "\n",
    "**INPUT:**  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **includeText8:** (boolean), if True, text8 corpus (wikipedia word dump) will be used in model training. [default = True]  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - it is reccomended to use the text 8 corpus unless you have a large enough corpus to successfuly train the model.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - More on text8 data : http://mattmahoney.net/dc/textdata  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **corpora:** (list) list of documents of which the model will be trained.     \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - Corpora should be a list of documents, which should be a list of sentences, which should be a list of words.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - An example input of a single document might look like : [[['the', 'cat', 'in', 'the', 'hat'],['the', 'grinch']]]  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - These documents should be pre-processed.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **epochsForTraining:** (list), (int), number of epochs desired for model training   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **word2VecArgs:** (dictionary), dictionary of Word2Vec model arguments please see Word2Vec for argument details. https://radimrehurek.com/gensim/models/word2vec.html  \n",
    "\n",
    "**OUTPUT:** gensim Word2Vec Model   \n",
    "\n",
    "**DESCRIPTION:** this function will allow for basic training of a gensim Word2Vec model. please see gensim documentation for more details on\n",
    "    model training. [https://radimrehurek.com/gensim/models/word2vec.html]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fiscal-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2VecArgs = {\n",
    "    'min_count': 2, \n",
    "    'size' : 100, \n",
    "    'workers': 3, \n",
    "    'window' : 5, \n",
    "    'sg' : 1\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    'includeText8' : True,\n",
    "    'corpora' : [labels['clean'].tolist(), recipes, grocery['clean'].tolist()],\n",
    "    'epochsForTraining' : 10,\n",
    "    'word2VecArgs' :  word2VecArgs\n",
    "}\n",
    "\n",
    "model = NS.trainModel(**parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
